---
title: "STAT 331 Portfolio"
author: "Aiden Kelly"
format: 
  html: 
    self-contained: true
layout: margin-left
editor: visual
execute: 
  eval: false
  echo: true
---

[**My Grade:**]{.underline} I believe my grade equivalent to course work evidenced below to be an A.

[**Learning Objective Evidence:**]{.underline} In the code chunks below, provide code from a Lab or Challenge assignment where you believe you have demonstrated proficiency with the specified learning target. Be sure to specify **where** the code came from (e.g., Lab 4 Question 2).

## Working with Data

**WD-1: I can import data from a *variety* of formats (e.g., csv, xlsx, txt, etc.).**

-   `csv`

```{r wd-1-csv}
# Lab 4 importing data
loan_17 <- read_csv(here::here('Labs', 'lab4', 'hmda_2017_ca_first-lien-owner-occupied-1-4-family-records_labels.csv'))
```

-   `xlsx`

```{r wd-1-xlsx}
# PA4 loading data
library(readxl) 
library(tidyverse)
military <- read_xlsx(here::here("data", 
                                 "gov_spending_per_capita.xlsx"), 
                      sheet = , 
                      skip = , 
                      nmax = )
```

-   `txt`

```{r wd-1-txt}
#PA5.2 loading data
message <- read_csv(here::here("5_strings-factors-dates", 
                                 "Practice Activity", 
                                 "scrambled_message.txt")
                    )
```

**WD-2: I can select necessary columns from a dataset.**

```{r wd-2}
# Challenge 3: Data Cleaning and Loading
hiphop_cln <- lyrics |>
  drop_na() |>
  mutate(word = as.factor(word), 
         subj = as.factor(subj),
         sex = as.factor(sex),
         ethnic = as.factor(ethnic), 
         wvnw = if_else(ethnic == "white", "white", "nonwhite")) |>
  distinct(subj, .keep_all = TRUE) |>
  select(subj, sex, wvnw, intl:hiphop)
```

**WD-3: I can filter rows from a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-3-numeric}
# Lab4: q1
avocado_major |>
  group_by(region) |>
  filter(year == 2017)
```

-   character -- specifically a string

```{r wd-3-string}
# Lab4: q1 - revised here
avocado_major |>
  group_by(region) |>
  filter(year == 2017, type == 'organic')
```

-   factor

```{r wd-3-factor}
#lab5: q3
rod_week <- surveys |>
  mutate(day_of_week = factor(day_of_week, levels = week_levels)) |>
  filter(!is.na(day_of_week)) |>
  group_by(day_of_week) |>
  summarise(Rodent_daily = n())
```

-   date

```{r wd-3-date}
#PA5.1: q1
suspects <- suspects %>% 
  filter(pm(Time.Spotted))
```

**WD-4: I can modify existing variables and create new variables in a dataframe for a *variety* of data types (e.g., numeric, integer, character, factor, date).**

-   numeric

```{r wd-4-numeric}
# Lab4: Reshaping 
mutate(real = across(.cols = LosAngeles:SanFrancisco, 
                       .fns = diff))
```

-   character -- specifically a string

```{r wd-4-string}
# Lab3: q7
hiphop_clean2 <- hiphop_clean |>
  mutate(wvnw = if_else(ethnic == "white", 
                        "white", 
                        "nonwhite"))
```

-   factor

```{r wd-4-factor}
# Lab5: q3
rod_week <- surveys |>
  filter(!is.na(day_of_week)) |>
  group_by(day_of_week) |>
  summarise(Rodent_daily = n()) |>
  mutate(day_of_week = factor(day_of_week, levels = week_levels))
```

-   date

```{r wd-4-date}
# Lab4: summaries, q2
month <- avocado |>
  separate(col = Date, 
           sep = "-", 
           into = c("Year",
                    "Month",
                    "Day"))
```

**WD-5: I can use mutating joins to combine multiple dataframes.**

-   `left_join()`

```{r wd-5-left}

```

-   `right_join()`

```{r wd-5-right}

```

-   `inner_join()`

```{r wd-5-inner}
# Lab4: reshaping, q1
means <- avocado_metro |>
  inner_join(cities)
```

-   `full_join()`

```{r wd-5-full}
#challenge 4: analysis
codomorg <- full_join(avocados, 
                      loan_clean_17, 
                      by = 'region')
```

**WD-6: I can use filtering joins to filter rows from a dataframe.**

-   `semi_join()`

```{r wd-6-semi}
# Lab4: data intro/ cleaning
avocado_major <- avocado |>
  semi_join(regions_major, 
            by = "region")
```

-   `anti_join()`

```{r wd-6-anti}
#PA5.1: q2
suspects <- suspects %>% 
  mutate(wday = wday(Time.Spotted, label = TRUE)) %>% 
  anti_join(closed, 
            by = "wday")
```

**WD-7: I can pivot dataframes from long to wide and visa versa**

-   `pivot_longer()`

```{r wd-7-long}
#Lab4: reshpaing, q1
means <- avocado_metro |>
  inner_join(cities) |>
  group_by(region, type) |> 
  summarise(small = mean(`Small Bags`),
            large = mean(`Large Bags`),
            XL = mean(`XLarge Bags`)) |>
  mutate(across(.cols = `small`:`XL`,
                .fns = ~.x / ( small + large + XL))) |>
  pivot_longer(cols = small:XL,
               names_to = "bag_size",
               values_to = "props")
```

-   `pivot_wider()`

```{r wd-7-wide}
#Lab4: reshaping, q1
cali_avocados <- avocado_metro |>
  semi_join(cities) |>
  group_by(region, type) |>
  summarise(prc = mean(`AveragePrice`)) |>
  pivot_wider(names_from = region, values_from = prc)
```

## Reproducibility

**R-1: I can create professional looking, reproducible analyses using RStudio projects, Quarto documents, and the here package.**

I've done this in the following provided assignments:

**R-2: I can write well documented and tidy code.**

-   Example 1

```{r r-2-1}
# challenge 4: anlysis
codomorg <- full_join(avocados, loan_clean_17, by = 'region') |>
  group_by(region) |>
  mutate(codos_needed = `med_cost` / `mean_prices`) |>
  mutate(years_needed = `codos_needed` / 365.25) 
```

-   Example 2

```{r r-2-2}
# Lab4: q5
# first 2 chunks r for finding the top 5 cities by mean sales
sidebside <- avocado_metro |> 
  group_by(region) |>
  summarise(meanTot = mean(`Total Volume`)) 

sidebside <- sidebside |>
  slice_max(meanTot, 
            n = 5) |>
  select(region)

# joins vector of regions with the og dataset to get the info on the sales
sidebyside <- avocado_metro |>
  semi_join(sidebside, by = "region")

ggplot(data = sidebyside, 
       mapping = aes(y = region, 
                     x = `Total Volume`)) + 
  geom_boxplot()
```

**R-3: I can write robust programs that are resistant to changes in inputs.**

-   Example 1

```{r r-3-1}
# lab 5: q3
week_levels <- c('Mon', 
                 'Tue',
                 'Wed',
                 'Thu',
                 'Fri',
                 'Sat',
                 'Sun')
rod_week <- surveys |>
  filter(!is.na(day_of_week)) |>
  group_by(day_of_week) |>
  summarise(Rodent_daily = n()) |>
  mutate(day_of_week = factor(day_of_week, levels = week_levels))
```

-   Example 2

```{r r-3-2}
# Lab4: q5

# first 2 chunks r for finding the top 5 cities by mean sales
sidebside <- avocado_metro |> 
  group_by(region) |>
  summarise(meanTot = mean(`Total Volume`)) 

sidebside <- sidebside |>
  slice_max(meanTot, 
            n = 5) |>
  select(region)
```

## Data Visualization & Summarization

**DVS-1: I can create visualizations for a *variety* of variable types (e.g., numeric, character, factor, date)**

-   numeric variables

```{r dvs-1-num}
# Lab2: q4 
ggplot(data = surveys, 
       mapping = aes(x = weight, 
                     y = hindfoot_length)) + 
  geom_point()
```

-   numeric variables and categorical variables

```{r dvs-2-num-cat}
# Lab2: q12
ggplot(data = surveys, 
       mapping = aes(x = weight, 
                     y= species) )  + 
  geom_jitter(color = 'tomato', 
              alpha = 0.2) + 
  geom_boxplot(outlier.shape = NA)
```

-   categorical variables

```{r dvs-2-cat}
#lab 5 q3
ggplot(data = day_or_end,
       mapping = aes(x = day_of_week,
                     y = `sum(Rodent_daily)`)) +
  geom_col(aes(fill = day_of_week)) + 
  labs(y = '',
       x = '',
       title = 'Rodents captured during the Week')
```

-   dates

```{r dvs-2-date}
# Lab5: q2
ggplot(data = rod_week,
       mapping = aes(x = day_of_week,
                     y = Rodent_daily)) +
  geom_col(aes(fill = day_of_week)) + 
  labs(y = '',
       title = 'Rodent per Day',
       x = '')
```

**DVS-2: I use plot modifications to make my visualization clear to the reader.**

-   Example 1

```{r dvs-2-1}
#lab2 q 12
ggplot(data = surveys, mapping = aes(x = weight, y = species) )  +
  geom_jitter(color = 'tomato', alpha = 0.2)+ geom_boxplot(outlier.shape = NA)
```

-   Example 2

```{r dvs-2-2}
# lab4 reshaping
means |>
  group_by(region) |>
  ggplot(mapping = aes(x = region,
                     y = props,
                     fill = `bag_size`)) +
         geom_col(position = "fill") + 
  facet_wrap(~type) +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  scale_fill_manual(values = c("#a6cee3", "#1f78b4", "#b2df8a")) + 
  labs(x = "Region of CA",
       y = "Proportion of mean avocados sold",
       fill = "Avocado Size")
```

**DVS-3: I show creativity in my visualizations**

-   Example 1

```{r dvs-3-1}
#challege 2
genescolor <- c("#e28743", "#022a5b", "#025b07", "#000306", "#45025b", "#97e87b", "#887be8", "#361cff", "#FFFF1C", "#1cffa7", "#1ccfff", "#881cff", "#80FF1C", "#FF1C20")

ggplot(data = surveys, 
       mapping = aes(x = weight, 
                     y = species, 
                     fill = species) )  + 
  scale_color_manual(values = genescolor) + 
  geom_jitter(color = 'tomato', 
              alpha = 0.2) + 
  geom_boxplot(outlier.shape = NA)
```

-   Example 2

```{r dvs-3-2}
# challenge 4: anaylsis
ggplot(data = codomorg,
       mapping = aes(x = region,
                     y = codos_needed)) + 
  geom_col(fill = c('red', 'blue', 'green', 'yellow')) +
  labs(x = "City of CA",
       y = "Avocados needed",
       title = "Avocados needed to buy a House")
```

**DVS-4: I can calculate numerical summaries of variables.**

-   Example 1

```{r dvs-4-1}
# Lab4: q3
sidebside <- avocado_metro |> 
  group_by(region) |>
  summarise(meanTot = mean(`Total Volume`))
```

-   Example 2

```{r dvs-4-2}
# lab 3: q11
hiphop_clean |>
  filter(age < 20) |>
  group_by(word) |>
  summarise(mean(familiarity))
```

**DVS-5: I can find summaries of variables across multiple groups.**

-   Example 1

```{r dvs-5-1}
#challenge3: white vs. nonwhite
hiphop_cln |>
  group_by(wvnw) |>
  summarise( across(
      intl:hiphop,
      mean))
```

-   Example 2

```{r dvs-5-2}
# challenge 3: Male vs. Female
hiphop_cln |>
  group_by(sex) |>
  summarise(across(intl:hiphop,
                   mean))
```

\*\*DVS-6: I can create tables which make my summaries clear to the reader.\*\*

\- Example 1

```{r dvs-6-1} # lab 9 importing data}
Anames <- read.csv(here('Labs', 'lab9', 'StateNames_A.csv'))
datatable(Anames)
```

\- Example 2

```{r dvs-6-2} # lab 9 q1}
temp |>
  kable(format = "html",
        caption = "==>Occurance of the name Allison by state and year<==") |>
  kable_classic(html_font = "FiraCode Nerd Font")
```

\*\*DVS-7: I show creativity in my tables.\*\*

\- Example 1

```{r dvs-7-1} # lab 9 q10 (revised here)}
# percents
percs <- percents(CA)
#rbind usuage found: https://www.statology.org/r-append-to-data-frame/
rbind(percs, percents(PA))  |>
  gt() |>
  tab_header(title =  "Occurance of the name Allison by state and year in %") |>
  fmt_percent(columns = 2:4, decimals = 2) 
```

\- Example 2

```{r dvs-7-2} # lab 9 q9}
CAvsPA |>
  kable(format = "html",
        caption = "==>Occurance of the  3 Alan names in PA and CA<==") |>
  kable_classic(html_font = "FiraCode Nerd Font")
```

## Program Efficiency

**PE-1: I can write concise code which does not repeat itself.**

-   using a single function call

```{r pe-1-one-call}
# Challenge 4 importing data
avocados <- read_csv(here::here('Labs', 'lab4', 'avocado.csv')) |>
  separate(col = Date, 
           sep = "-", 
           into = c("Year",
                    "Month",
                    "Day")) |>
    filter(region == c('SanDiego', 
                     'LosAngeles', 
                     'Sacramento', 
                     'SanFrancisco'),
           Year == '2017') |>
  select(region, AveragePrice) |>
  group_by(region) |>
  summarise(mean_prices = mean(AveragePrice))

```

-   `across()`

```{r pe-1-across}
# Lab 4: reshaping q1
cali_avocados <- avocado_metro |>
  semi_join(cities) |>
  group_by(region, type) |>
  summarise(prc = mean(`AveragePrice`)) |>
  pivot_wider(names_from = region, values_from = prc) |>
  mutate(real = across(.cols = LosAngeles:SanFrancisco, 
                       .fns = diff))
```

**PE-2: I can write functions to reduce repetition in my code.**

\- Example 1

```{r pe2-1}
# lab8 Full phrase part
make_phrase <- function(Day, Day.in.Words, Gift.Item, Verb, Adjective, Location, spice) {
  
  ## Step 1: Replace NAs with blank strings
  Verb <- str_replace_na(Verb, '')
  Adjective <- str_replace_na(Adjective, '')
  Location <- str_replace_na(Location, '')
  
  ## Step 2: If the day is larger than 1, the items need pluralized! 
  Gift.Item <- case_when(Day.in.Words != 'first' ~ pluralize_gift(Gift.Item),
                         .default = Gift.Item)
  
  ## Step 3: If the day is 1, you need to add an "a" or "an" before the gift 
  Gift.Item <- case_when(Day.in.Words == 'first' & str_starts(Gift.Item, "[aeiouy]")~ str_c('an', Gift.Item), 
                         Day.in.Words == 'first' & str_starts(Gift.Item, "[^aeiouy]")~ str_c('a ', Gift.Item),
                         .default = Gift.Item)
  
  ## Step 4: Glue all of the pieces together to make a phrase! 
 if(Day.in.Words == 'first'){
   
    return(glue('{Gift.Item} {Location}'))
   
 }else{
   
   return(glue('{english(Day)} {Adjective} {Gift.Item} {Verb}'))
 }
  
}
```

\- Example 2

```{r pe2-2}
# lab 7 part 3.2 adding stops
tryagain <- function(sd){
  
  stopifnot(is.numeric(sd), !length(sd) == 0)

  sd_range <- range(sd, na.rm = T)
  if(sd_range[[1]] == 0 & sd_range[[2]] == 1){
    print('Looks good to me!')
  }else{
    print('It doesn\'t look good to me :(')
  }

}
```

**PE-3: I can use iteration to reduce repetition in my code.**

-   `across()`

```{r pe-3-across}
# Lab 4: reshaping q1
cali_avocados <- avocado_metro |>
  semi_join(cities) |>
  group_by(region, type) |>
  summarise(prc = mean(`AveragePrice`)) |>
  pivot_wider(names_from = region, values_from = prc) |>
  mutate(real = across(.cols = LosAngeles:SanFrancisco, 
                       .fns = diff))
```

\- \`map()\` functions (Provide 2 Examples)

```{r pe-3-map-1}
# lab 8 full song (last question)
song <- map_chr(.x = 1:12,
        .f  = ~ sing_day(xmas2, .x, Full.Phrase))
```

```{r pe-3-map-2}
# lab 8 full phrase part
xmas2 <- xmas |>
  mutate(Full.Phrase = pmap_chr(xmas, 
                                make_phrase))
```

**PE-4: I can use modern tools when carrying out my analysis.**

-   Example 1 - using slice

```{r pe-4-1}
# Lab4: summaries #3 
sidebside <- sidebside |>
  slice_max(meanTot, 
            n = 5) |>
  select(region)

```

-   Example 2 - using here

```{r pe-4-2}
# challenge 2: importing data 
library('tidyverse')
surveys <- read_csv(here::here('Labs', 'lab2', 'surveys.csv'))

```

## Data Simulation & Modeling

**DSM-1: I can simulate data from a \_variety\_ of probability models.**

\- Example 1

```{r dsm-1-1}
# practice 9 q3
music_man <- function(n_tromb, n_cor, n_reed){
  
  cornets <- runif(n_cor,
                   min = 1.5,
                   max = 3.5)
  trombones <- rnorm(n_tromb, 
                     mean = 4.6, 
                     sd = .8)
  reeds <- rchisq(n_reed,
                  df = 4)
  
  return(sum(cornets, cornets, reeds))
  
}
```

\- Example 2

```{r dsm-1-2}
#practice 9 q3
normdist <- rnorm(100, 
                  mean = 4.6, 
                  sd = .8)
```

**DSM-2: I can fit a linear regression and extract necessary summary measures.**

\- Example 1

```{r dsm-2-1}

```

\- Example 2

```{r dsm-2-2} # lab 9 q4}
allison_linear <- allison_f |>
  summarise(across(.col = `1997`:`2014`,
                   .fns = ~sum(.x))) |>
  pivot_longer(cols = `1997`:`2014`,
               values_to = 'Count') |>
  mutate(`name` = as.numeric(`name`)) |>
  lm(`Count` ~ `name`, data = _)

#residuals vs. order
allison_linear |> 
  broom::augment() |> 
  ggplot(mapping = aes(y = .resid, x = .fitted)) +
  geom_point()

```

## Revising My Thinking

When doing revising I try to think about how the comments given will help me reinforce good practices as I continue in my programming career. I also try to think some of the learning targets, mostly efficiency, code resistant to changes, and using modern tools. For example, when looking back for the portfolio, I noticed I had a lot of formatting errors in my earlier projects but became a lot better over time. I also noticed my use of bar plots for vars that were not proportions/ percentages, so going forward I am going to remember to not use them. Some efficiency things that I noticed was that in lab 4 I was using dataframes for a join when I should have used a tibble, and also in lab 5, I was creating new factors to modify the levels rather than using the fct_reorder function (a modern tool).

## Extending My Thinking

Much like I mentioned in my reflection from week 4, I feel like most of my extended thinking comes from areas of interest. Expanding, I think I also realized I like to do a lot more of the analysis and trying to incorporate research from external sources and combining it with my knowledge from the course. Additionally, I realized my extending rarely is reflected in my visualizations, which is something I want to work on for the rest of the quarter because I think that visualizations are really important for statisticians and data scientists.

## Peer Support & Collaboration

Your code looks very good! I think there are a few formatting mistakes. There were a couple times when you didn't do a new line after a comma. Your graphs look really good. I really like how you color coded your conv vs. avocado plot by avocado type. Additionally, I really like how you used very efficient code, like using the labs function on your ggplot and the joins we were taught that week. Overall great job!
